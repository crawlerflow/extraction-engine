{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Web Parser Introduction Simple, extendable HTML and XML data extraction engine using YAML configurations and some times pythonic extractors. Requirements Python 3.6, 3.7 and 3.8 Simple Usage from web_parser import HTMLParser from web_parser.manifest import HTMLExtractionManifest import urllib.request import yaml html_string = urllib.request.urlopen(\"https://invana.io\").read().decode(\"utf-8\") extraction_manifest_yaml = \"\"\" - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: title element_query: type: css value: title data_attribute: text data_type: StringField \"\"\" extraction_manifest = yaml.load(extraction_manifest_yaml, yaml.Loader) manifest = HTMLExtractionManifest( title=\"invana.io blogs\", domain=\"invana.io\", version=\"beta\", test_urls=\"https://invana.io/blogs\", owner={ \"title\": \"Ravi Raja Merugu\", \"ownership_type\": \"Individual\", \"email\": \"rrmerugu@gmail.com\", \"website_url\": \"https://rrmerugu.github.io\" }, extractors=extraction_manifest ) engine = HTMLParser(html_string=html_string, url=\"http://dummy-url.com\", extraction_manifest=manifest) data = engine.run(flatten_extractors=False) print(data) License Copyright 2020 Invana Technology Solutions Pvt Ltd Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Home"},{"location":"#web-parser","text":"","title":"Web Parser"},{"location":"#introduction","text":"Simple, extendable HTML and XML data extraction engine using YAML configurations and some times pythonic extractors.","title":"Introduction"},{"location":"#requirements","text":"Python 3.6, 3.7 and 3.8","title":"Requirements"},{"location":"#simple-usage","text":"from web_parser import HTMLParser from web_parser.manifest import HTMLExtractionManifest import urllib.request import yaml html_string = urllib.request.urlopen(\"https://invana.io\").read().decode(\"utf-8\") extraction_manifest_yaml = \"\"\" - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: title element_query: type: css value: title data_attribute: text data_type: StringField \"\"\" extraction_manifest = yaml.load(extraction_manifest_yaml, yaml.Loader) manifest = HTMLExtractionManifest( title=\"invana.io blogs\", domain=\"invana.io\", version=\"beta\", test_urls=\"https://invana.io/blogs\", owner={ \"title\": \"Ravi Raja Merugu\", \"ownership_type\": \"Individual\", \"email\": \"rrmerugu@gmail.com\", \"website_url\": \"https://rrmerugu.github.io\" }, extractors=extraction_manifest ) engine = HTMLParser(html_string=html_string, url=\"http://dummy-url.com\", extraction_manifest=manifest) data = engine.run(flatten_extractors=False) print(data)","title":"Simple Usage"},{"location":"#license","text":"Copyright 2020 Invana Technology Solutions Pvt Ltd Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"manifest/","text":"manifest.yml Manifest is the configuration that contains both author information and the instructions to extract data from HTML/XML. Example Usage from web_parser.manifest.v1 import HTMLExtractionManifest manifest = HTMLExtractionManifest( title=\"invana.io blogs\", domain=\"invana.io\", version=\"beta\", test_urls=[\"https://invana.io/blogs\",], owner={ \"title\": \"Ravi Raja Merugu\", \"ownership_type\": \"Individual\", \"email\": \"rrmerugu@gmail.com\", \"website_url\": \"https://rrmerugu.github.io\" }, extractors=[] # <---- here comes the actual manifest ) 1. Types of Extractors Web Parser provides three types of extractors for data extraction from HTML. Standard Extractors - extract data from standard html tags Custom Data Extractor - extract data using your own elements and data attribute extraction Python Extractor 1. Standard Extractors To cover the most standard needs of data extraction, we have built standard extractors, which extract from standard html tags like Paragraphs, Headings, Anchor tags, meta tags, JSON+LD, tables, ordered and unordered lists. from web_parser.extractors.html.content import PageOverviewExtractor, \\ ParagraphsExtractor, HeadingsExtractor, TableContentExtractor, MetaTagExtractor, IconsExtractor, JSONLDExtractor, \\ FeedUrlExtractor, PlainHTMLContentExtractor, MainContentExtractor 1.1 MetaTagExtractor Example This below extractor configuration will extract all <meta> tags data. - extractor_type: MetaTagExtractor extractor_id: meta_tags # result { \"meta_tags\": { \"meta__description\": \"Connect to your databases, microservices or data from internet and create Knowledge & Data APIs in near realtime\", \"meta__viewport\": \"width=device-width, initial-scale=1\", \"title\": \"Use Cases | Invana\" } } 1.2 ParagraphsExtractor Example - extractor_type: ParagraphsExtractor extractor_id: paragraphs # result { \"paragraphs\": [ \"Connect to your databases, microservices or data from internet and create Knowledge & Data APIs in near realtime\", ] } 1.3 PageOverviewExtractor Example - extractor_type: PageOverviewExtractor extractor_id: overview # result {'overview': { 'canonical_url': None, 'description': 'Connect to your databases, microservices or data from internet and create Knowledge & Data APIs ' 'in near realtime', 'domain': 'invana.io', 'first_paragraph': 'Invana is an open source distributed processing engine aiming to allow you run ' 'microservices on top of your data(static or streams), giving you a', 'image': None, 'keywords': None, 'page_type': None, 'shortlink_url': None, 'title': 'Enrich your data with information available on the Internet | Invana', 'url': None } } 2. Custom Data Extractor We need to define data extractor configuration in yaml format, with each field_id to extract in the format field. All the custom data extractor should have extractor_fields defined along with extractor_id and extractor_type . Each data field should be defined as: - field_id: title element_query: type: css value: title data_attribute: text data_type: StringField 2.1 Extracting flat data. - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: title element_query: type: css value: title data_attribute: text data_type: StringField - field_id: first_paragraph element_query: type: css value: p data_attribute: text data_type: StringField - field_id: image element_query: type: css value: .hero-image data_attribute: src data_type: StringField #result { \"title\": \"Invana\", \"first_paragraph\": \"Invana is an open source distributed processing engine aiming to allow you run microservices on top of your data(static or streams), giving you a production-ready Knowledge and Data APIs in near realtime.\" \"image\": \"https://invana.io/image/hero-image.png\" } 2.2 Extracting items with sub data. To extract data like product items from e-commerce sites like amazon or blogs from any sites, we need to extract list of blogs data including the fields like title, price, image, description etc. That is when we should use something like below, which lets us extract html elements with selector_query and assign ListDictField as we are going to extract list of dictionary elements. data_attribute: element data_type: ListDictField The full configuration would look like this, - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: use_cases element_query: type: css value: .card-body data_attribute: element data_type: ListDictField child_selectors: - field_id: heading element_query: type: css value: h3 data_attribute: text data_type: StringField - field_id: body element_query: type: css value: p data_attribute: text data_type: StringField #result {'use_cases': [ { 'body': 'Automate anything on the web ...' 'heading': 'Web Automation ...' },... ] } 2. Types of Data types Each field_id , should be assigned a data type, so that the data will be saved in the format, that can be used for indexing the data. Valid data types are : RawField ListRawField StringField ListStringField IntField ListIntField FloatField ListFloatField DictField ListDictField","title":"Manifest"},{"location":"manifest/#manifestyml","text":"Manifest is the configuration that contains both author information and the instructions to extract data from HTML/XML.","title":"manifest.yml"},{"location":"manifest/#example-usage","text":"from web_parser.manifest.v1 import HTMLExtractionManifest manifest = HTMLExtractionManifest( title=\"invana.io blogs\", domain=\"invana.io\", version=\"beta\", test_urls=[\"https://invana.io/blogs\",], owner={ \"title\": \"Ravi Raja Merugu\", \"ownership_type\": \"Individual\", \"email\": \"rrmerugu@gmail.com\", \"website_url\": \"https://rrmerugu.github.io\" }, extractors=[] # <---- here comes the actual manifest )","title":"Example Usage"},{"location":"manifest/#1-types-of-extractors","text":"Web Parser provides three types of extractors for data extraction from HTML. Standard Extractors - extract data from standard html tags Custom Data Extractor - extract data using your own elements and data attribute extraction Python Extractor","title":"1. Types of Extractors"},{"location":"manifest/#1-standard-extractors","text":"To cover the most standard needs of data extraction, we have built standard extractors, which extract from standard html tags like Paragraphs, Headings, Anchor tags, meta tags, JSON+LD, tables, ordered and unordered lists. from web_parser.extractors.html.content import PageOverviewExtractor, \\ ParagraphsExtractor, HeadingsExtractor, TableContentExtractor, MetaTagExtractor, IconsExtractor, JSONLDExtractor, \\ FeedUrlExtractor, PlainHTMLContentExtractor, MainContentExtractor","title":"1. Standard Extractors"},{"location":"manifest/#11-metatagextractor-example","text":"This below extractor configuration will extract all <meta> tags data. - extractor_type: MetaTagExtractor extractor_id: meta_tags # result { \"meta_tags\": { \"meta__description\": \"Connect to your databases, microservices or data from internet and create Knowledge & Data APIs in near realtime\", \"meta__viewport\": \"width=device-width, initial-scale=1\", \"title\": \"Use Cases | Invana\" } }","title":"1.1 MetaTagExtractor Example"},{"location":"manifest/#12-paragraphsextractor-example","text":"- extractor_type: ParagraphsExtractor extractor_id: paragraphs # result { \"paragraphs\": [ \"Connect to your databases, microservices or data from internet and create Knowledge & Data APIs in near realtime\", ] }","title":"1.2 ParagraphsExtractor Example"},{"location":"manifest/#13-pageoverviewextractor-example","text":"- extractor_type: PageOverviewExtractor extractor_id: overview # result {'overview': { 'canonical_url': None, 'description': 'Connect to your databases, microservices or data from internet and create Knowledge & Data APIs ' 'in near realtime', 'domain': 'invana.io', 'first_paragraph': 'Invana is an open source distributed processing engine aiming to allow you run ' 'microservices on top of your data(static or streams), giving you a', 'image': None, 'keywords': None, 'page_type': None, 'shortlink_url': None, 'title': 'Enrich your data with information available on the Internet | Invana', 'url': None } }","title":"1.3 PageOverviewExtractor Example"},{"location":"manifest/#2-custom-data-extractor","text":"We need to define data extractor configuration in yaml format, with each field_id to extract in the format field. All the custom data extractor should have extractor_fields defined along with extractor_id and extractor_type . Each data field should be defined as: - field_id: title element_query: type: css value: title data_attribute: text data_type: StringField","title":"2. Custom Data Extractor"},{"location":"manifest/#21-extracting-flat-data","text":"- extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: title element_query: type: css value: title data_attribute: text data_type: StringField - field_id: first_paragraph element_query: type: css value: p data_attribute: text data_type: StringField - field_id: image element_query: type: css value: .hero-image data_attribute: src data_type: StringField #result { \"title\": \"Invana\", \"first_paragraph\": \"Invana is an open source distributed processing engine aiming to allow you run microservices on top of your data(static or streams), giving you a production-ready Knowledge and Data APIs in near realtime.\" \"image\": \"https://invana.io/image/hero-image.png\" }","title":"2.1 Extracting flat data."},{"location":"manifest/#22-extracting-items-with-sub-data","text":"To extract data like product items from e-commerce sites like amazon or blogs from any sites, we need to extract list of blogs data including the fields like title, price, image, description etc. That is when we should use something like below, which lets us extract html elements with selector_query and assign ListDictField as we are going to extract list of dictionary elements. data_attribute: element data_type: ListDictField The full configuration would look like this, - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: use_cases element_query: type: css value: .card-body data_attribute: element data_type: ListDictField child_selectors: - field_id: heading element_query: type: css value: h3 data_attribute: text data_type: StringField - field_id: body element_query: type: css value: p data_attribute: text data_type: StringField #result {'use_cases': [ { 'body': 'Automate anything on the web ...' 'heading': 'Web Automation ...' },... ] }","title":"2.2 Extracting items with sub data."},{"location":"manifest/#2-types-of-data-types","text":"Each field_id , should be assigned a data type, so that the data will be saved in the format, that can be used for indexing the data. Valid data types are : RawField ListRawField StringField ListStringField IntField ListIntField FloatField ListFloatField DictField ListDictField","title":"2. Types of Data types"},{"location":"tutorials/html-extractor/","text":"HTML Extractor Regular data extractor from web_parser import HTMLParser from web_parser.manifest import HTMLExtractionManifest import urllib.request import yaml html_string = urllib.request.urlopen(\"https://invana.io\").read().decode(\"utf-8\") extraction_manifest_yaml = \"\"\" - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: title element_query: type: css value: title data_attribute: text data_type: StringField \"\"\" extraction_manifest = yaml.load(extraction_manifest_yaml, yaml.Loader) manifest = HTMLExtractionManifest( title=\"invana.io blogs\", domain=\"invana.io\", version=\"beta\", test_urls=\"https://invana.io/blogs\", owner={ \"title\": \"Ravi Raja Merugu\", \"ownership_type\": \"Individual\", \"email\": \"rrmerugu@gmail.com\", \"website_url\": \"https://rrmerugu.github.io\" }, extractors=extraction_manifest ) engine = HTMLParser(html_string=html_string, url=\"http://dummy-url.com\", extraction_manifest=manifest) data = engine.run(flatten_extractors=False) print(data) {'content': {'title': 'Enrich your data with information available on the Internet | Invana'}} data = engine.run(flatten_extractors=True) # this will remove the `content` which is the extractor id, {'title': 'Enrich your data with information available on the Internet | Invana'} With child selectors from web_parser import HTMLParser from web_parser.manifest import HTMLExtractionManifest import urllib.request import yaml html_string = urllib.request.urlopen(\"https://invana.io/use-cases.html\").read().decode(\"utf-8\") extraction_manifest_yaml = \"\"\" - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: use_cases element_query: type: css value: .card-body data_attribute: element data_type: ListDictField child_selectors: - field_id: heading element_query: type: css value: h3 data_attribute: text data_type: StringField - field_id: body element_query: type: css value: p data_attribute: text data_type: StringField \"\"\" extraction_manifest = yaml.load(extraction_manifest_yaml, yaml.Loader) manifest = HTMLExtractionManifest( title=\"invana.io blogs\", domain=\"invana.io\", version=\"beta\", test_urls=\"https://invana.io/blogs\", owner={ \"title\": \"Ravi Raja Merugu\", \"ownership_type\": \"Individual\", \"email\": \"rrmerugu@gmail.com\", \"website_url\": \"https://rrmerugu.github.io\" }, extractors=extraction_manifest ) engine = HTMLParser(html_string=html_string, url=\"http://dummy-url.com\", extraction_manifest=manifest) data = engine.run(flatten_extractors=False) print(data) {'content': {'use_cases': [{'body': 'Automate anything on the web with ' 'browsers. Post data or crawl and fetch ' 'structured information from any a single ' 'webpage or from a pool of websites.', 'heading': 'Web Automation'}, {'body': \"Invana GraphQL API's gives you instant \" 'APIs without coding, giving you power to ' 'rapidly experiment with your data schemas ' 'that work for you.', 'heading': 'Rapid Prototyping'}, {'body': 'Invana gives you easy and potential to \\n' ' run microservices ' 'that range from simple text or image ' 'processing functions to Machine Learning ' 'models', 'heading': 'Run Microservices on stream'}, {'body': \"Invana let's you analyse, compute and do \" 'operatoins on your stream data to produce ' 'knowledge and facts needed for your ' 'Machine Learning Projects.', 'heading': 'Build Knowledge Graphs'}, {'body': \"Invana let's you crawl through data \" 'available on the internet or from your ' 'data buckets or databases and gives a ' 'scalable search API.', 'heading': 'Instantly Build Search APIs'}]}} data = engine.run(flatten_extractors=True) print(data) {'use_cases': [{'body': 'Automate anything on the web with browsers. Post data ' 'or crawl and fetch structured information from any a ' 'single webpage or from a pool of websites.', 'heading': 'Web Automation'}, {'body': \"Invana GraphQL API's gives you instant APIs without \" 'coding, giving you power to rapidly experiment with ' 'your data schemas that work for you.', 'heading': 'Rapid Prototyping'}, {'body': 'Invana gives you easy and potential to \\n' ' run microservices that range ' 'from simple text or image processing functions to ' 'Machine Learning models', 'heading': 'Run Microservices on stream'}, {'body': \"Invana let's you analyse, compute and do operatoins \" 'on your stream data to produce knowledge and facts ' 'needed for your Machine Learning Projects.', 'heading': 'Build Knowledge Graphs'}, {'body': \"Invana let's you crawl through data available on the \" 'internet or from your data buckets or databases and ' 'gives a scalable search API.', 'heading': 'Instantly Build Search APIs'}]} Flatten Extracted data # look at the above example for a practical example with code. engine = HTMLParser(html_string=html_string, url=\"http://dummy-url.com\", extraction_manifest=manifest) data = engine.run(flatten_extractors=True)","title":"HTML Extractor"},{"location":"tutorials/html-extractor/#html-extractor","text":"","title":"HTML Extractor"},{"location":"tutorials/html-extractor/#regular-data-extractor","text":"from web_parser import HTMLParser from web_parser.manifest import HTMLExtractionManifest import urllib.request import yaml html_string = urllib.request.urlopen(\"https://invana.io\").read().decode(\"utf-8\") extraction_manifest_yaml = \"\"\" - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: title element_query: type: css value: title data_attribute: text data_type: StringField \"\"\" extraction_manifest = yaml.load(extraction_manifest_yaml, yaml.Loader) manifest = HTMLExtractionManifest( title=\"invana.io blogs\", domain=\"invana.io\", version=\"beta\", test_urls=\"https://invana.io/blogs\", owner={ \"title\": \"Ravi Raja Merugu\", \"ownership_type\": \"Individual\", \"email\": \"rrmerugu@gmail.com\", \"website_url\": \"https://rrmerugu.github.io\" }, extractors=extraction_manifest ) engine = HTMLParser(html_string=html_string, url=\"http://dummy-url.com\", extraction_manifest=manifest) data = engine.run(flatten_extractors=False) print(data) {'content': {'title': 'Enrich your data with information available on the Internet | Invana'}} data = engine.run(flatten_extractors=True) # this will remove the `content` which is the extractor id, {'title': 'Enrich your data with information available on the Internet | Invana'}","title":"Regular data extractor"},{"location":"tutorials/html-extractor/#with-child-selectors","text":"from web_parser import HTMLParser from web_parser.manifest import HTMLExtractionManifest import urllib.request import yaml html_string = urllib.request.urlopen(\"https://invana.io/use-cases.html\").read().decode(\"utf-8\") extraction_manifest_yaml = \"\"\" - extractor_type: CustomDataExtractor extractor_id: content extractor_fields: - field_id: use_cases element_query: type: css value: .card-body data_attribute: element data_type: ListDictField child_selectors: - field_id: heading element_query: type: css value: h3 data_attribute: text data_type: StringField - field_id: body element_query: type: css value: p data_attribute: text data_type: StringField \"\"\" extraction_manifest = yaml.load(extraction_manifest_yaml, yaml.Loader) manifest = HTMLExtractionManifest( title=\"invana.io blogs\", domain=\"invana.io\", version=\"beta\", test_urls=\"https://invana.io/blogs\", owner={ \"title\": \"Ravi Raja Merugu\", \"ownership_type\": \"Individual\", \"email\": \"rrmerugu@gmail.com\", \"website_url\": \"https://rrmerugu.github.io\" }, extractors=extraction_manifest ) engine = HTMLParser(html_string=html_string, url=\"http://dummy-url.com\", extraction_manifest=manifest) data = engine.run(flatten_extractors=False) print(data) {'content': {'use_cases': [{'body': 'Automate anything on the web with ' 'browsers. Post data or crawl and fetch ' 'structured information from any a single ' 'webpage or from a pool of websites.', 'heading': 'Web Automation'}, {'body': \"Invana GraphQL API's gives you instant \" 'APIs without coding, giving you power to ' 'rapidly experiment with your data schemas ' 'that work for you.', 'heading': 'Rapid Prototyping'}, {'body': 'Invana gives you easy and potential to \\n' ' run microservices ' 'that range from simple text or image ' 'processing functions to Machine Learning ' 'models', 'heading': 'Run Microservices on stream'}, {'body': \"Invana let's you analyse, compute and do \" 'operatoins on your stream data to produce ' 'knowledge and facts needed for your ' 'Machine Learning Projects.', 'heading': 'Build Knowledge Graphs'}, {'body': \"Invana let's you crawl through data \" 'available on the internet or from your ' 'data buckets or databases and gives a ' 'scalable search API.', 'heading': 'Instantly Build Search APIs'}]}} data = engine.run(flatten_extractors=True) print(data) {'use_cases': [{'body': 'Automate anything on the web with browsers. Post data ' 'or crawl and fetch structured information from any a ' 'single webpage or from a pool of websites.', 'heading': 'Web Automation'}, {'body': \"Invana GraphQL API's gives you instant APIs without \" 'coding, giving you power to rapidly experiment with ' 'your data schemas that work for you.', 'heading': 'Rapid Prototyping'}, {'body': 'Invana gives you easy and potential to \\n' ' run microservices that range ' 'from simple text or image processing functions to ' 'Machine Learning models', 'heading': 'Run Microservices on stream'}, {'body': \"Invana let's you analyse, compute and do operatoins \" 'on your stream data to produce knowledge and facts ' 'needed for your Machine Learning Projects.', 'heading': 'Build Knowledge Graphs'}, {'body': \"Invana let's you crawl through data available on the \" 'internet or from your data buckets or databases and ' 'gives a scalable search API.', 'heading': 'Instantly Build Search APIs'}]}","title":"With child selectors"},{"location":"tutorials/html-extractor/#flatten-extracted-data","text":"# look at the above example for a practical example with code. engine = HTMLParser(html_string=html_string, url=\"http://dummy-url.com\", extraction_manifest=manifest) data = engine.run(flatten_extractors=True)","title":"Flatten Extracted data"},{"location":"tutorials/xml-extractor/","text":"XML Extractor","title":"XML Extractor"},{"location":"tutorials/xml-extractor/#xml-extractor","text":"","title":"XML Extractor"}]}